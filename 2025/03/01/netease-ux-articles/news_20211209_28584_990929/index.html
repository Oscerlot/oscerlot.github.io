<!DOCTYPE html>
<html lang="en">
  <head><!-- hexo injector head_begin start --><!-- Google tag (gtag.js) begins-->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-NDVFDN1ZLY"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
    
      gtag('config', 'G-NDVFDN1ZLY');
    </script>
    <!-- Google tag (gtag.js) ends-->
    <!-- hexo injector head_begin end -->
    <meta charset="UTF-8">
<meta name="viewport"
      content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">

    <meta name="author" content="Oscar Armstrong-Davies">







<title>Recommendation Systems: The MAB Problem and Bandit Algorithms | oad</title>



    <link rel="icon" href="/favicon.ico">



<style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=Noto+Sans+SC:wght@300;400;500;700&family=Roboto+Mono&display=swap');
</style>



    <!-- stylesheets list from _config.yml -->
    
    <link rel="stylesheet" href="/css/style.css">
    




    <!-- scripts list from _config.yml -->
    
    <script src="/js/menu.js"></script>
    










  <meta name="generator" content="Hexo 7.3.0"></head>
  <body>
    <div class="mask-border">
    </div>

    <div class="wrapper">

      <div class="header">
  <div class="flex-container">
    <div class="header-inner">
      <div class="site-brand-container">
        <a href="/">
          
            oad.
          
        </a>
      </div>
      <div id="menu-btn" class="menu-btn" onclick="toggleMenu()">
        Menu
      </div>
      <nav class="site-nav">
        <ul class="menu-list">
          
            
              <li class="menu-item">
                <a href="/archives/">Archive</a>
              </li> 
                   
          
          
            <li class="menu-item search-btn">
              <a href="#">Search</a>
            </li>
          
        </ul>
      </nav>
    </div>
  </div>
</div>


      <div class="main">
        <div class="flex-container">
          <article id="post">

  
    <div class="post-head">
    <div class="post-info">
        <div class="tag-list">
            
                
                    <span class="post-tag">
                        <a href="/tags/Recommendation-System/">
                            Recommendation System
                        </a>
                    </span>    
                
                    <span class="post-tag">
                        <a href="/tags/MAB-Problem/">
                            MAB Problem
                        </a>
                    </span>    
                
                    <span class="post-tag">
                        <a href="/tags/Bandit-Algorithm/">
                            Bandit Algorithm
                        </a>
                    </span>    
                
                    <span class="post-tag">
                        <a href="/tags/Thompson-Sampling/">
                            Thompson Sampling
                        </a>
                    </span>    
                
                    <span class="post-tag">
                        <a href="/tags/Exploit-Explore/">
                            Exploit-Explore
                        </a>
                    </span>    
                
                    <span class="post-tag">
                        <a href="/tags/Beta-Distribution/">
                            Beta Distribution
                        </a>
                    </span>    
                           
            
        </div>
        <div class="post-title">
            
            
                Recommendation Systems: The MAB Problem and Bandit Algorithms
            
            
        </div>
        <span class="post-date">
            1 Mar, 2025
        </span>
    </div>
    <div class="post-img">
        
            <div class="h-line-primary"></div>
              
    </div>
</div>
    <div class="post-content">
    <blockquote>
<p><em>Machine Translated from Chinese to English</em><br><a target="_blank" rel="noopener" href="https://ux.163.com/news/20211209/28584_990929.html"><em><strong>Original article written by ThunderFire UX (NetEase)</strong></em></a></p>
</blockquote>
<p>In recommendation systems, it is necessary to find a balance between exploration (exploring unknown areas) and exploitation (exploiting existing knowledge), which is the Exploit-Explore problem. Exploitation can be understood as recommending things that users are definitely interested in, while exploration can be understood as trying to discover users’ new interests. Otherwise, repeatedly recommending things that users are interested in will make users feel fatigued. However, constantly exploring new interests will inevitably affect the user’s click-through rate. Making trade-offs between exploration and exploitation is a challenge in developing recommendation systems.</p>
<h2 id="I-The-MAB-Problem"><a href="#I-The-MAB-Problem" class="headerlink" title="I. The MAB Problem"></a>I. The MAB Problem</h2><p>In fact, the above problem can be abstracted as an MAB problem (Multi-armed bandit problem). As the name suggests, it originated in casinos.  A gambler enters a casino and there are multiple slot machines. Each slot machine has a different probability of winning.  How can the gambler learn the winning distribution of each machine and develop a strategy to maximize profit?</p>
<p>&nbsp;<br><img src="https://img.notionusercontent.com/ext/https%3A%2F%2Fnie.res.netease.com%2Fr%2Fpic%2F20211209%2Fb4a85839-b998-4c7c-ad72-0397fa1c4157.png/size/" alt="https:&#x2F;&#x2F;nie.res.netease.com&#x2F;r&#x2F;pic&#x2F;20211209&#x2F;b4a85839-b998-4c7c-ad72-0397fa1c4157.png"></p>
<h2 id="II-Bandit-Algorithms"><a href="#II-Bandit-Algorithms" class="headerlink" title="II. Bandit Algorithms"></a>II. Bandit Algorithms</h2><p>To solve this problem, you can try using Bandit algorithms. Bandit algorithms are actually a general term for a class of algorithms. The basic idea can be summarized in two points:</p>
<ol>
<li>For a choice, if the number of experiments is large enough and the return is greater, then we are more inclined to choose it, and vice versa.</li>
<li>For a choice, if the number of experiments is too small to determine whether the choice is good or bad, then try it a few more times until its quality is determined.</li>
</ol>
<h2 id="III-Thompson-Sampling-Algorithm"><a href="#III-Thompson-Sampling-Algorithm" class="headerlink" title="III. Thompson Sampling Algorithm"></a>III. Thompson Sampling Algorithm</h2><p>Due to space limitations, this article only introduces a common Bandit algorithm: the Thompson sampling algorithm. Its principle is: in the candidate pool, the revenue generated by choosing each item follows a separate probability distribution. Each time a selection is made, a random number is generated from the probability distribution of each item.  Finally, the item corresponding to the largest random number is recommended.</p>
<p>This probability distribution is the Beta distribution. Its probability distribution function is shown below:</p>
<p>&nbsp;<br><img src="https://img.notionusercontent.com/ext/https%3A%2F%2Fnie.res.netease.com%2Fr%2Fpic%2F20211209%2F0380abed-d53b-46c3-8b79-5777e75552f7.png/size/" alt="https:&#x2F;&#x2F;nie.res.netease.com&#x2F;r&#x2F;pic&#x2F;20211209&#x2F;0380abed-d53b-46c3-8b79-5777e75552f7.png"></p>
<ul>
<li><p>The Beta distribution has two parameters, α and β, which determine the shape of the distribution curve:</p>
<ol>
<li>When α + β is larger, the curve will be narrower and the distribution will be more concentrated. Conversely, the curve will be wider and the distribution will be more dispersed.</li>
<li>When α &#x2F; (α + β) is larger, the center position of the distribution is closer to 1, and vice versa, it is closer to 0.</li>
</ol>
</li>
<li><p>Applying this characteristic of the Beta distribution to the recommendation system, the number of times a user clicks on an item is regarded as the parameter α, and the number of times it is recommended but not clicked is regarded as the parameter β. Then there can be the following 3 situations:</p>
<ol>
<li>When α + β of an item is large enough (the number of times it has been recommended is large enough), its distribution will be very narrow, that is, we are already very sure of the return of recommending this item. At this time, the return generated according to the Beta distribution is close to its average return.</li>
<li>When α + β of an item is large enough and α &#x2F; (α + β) is larger (the number of times it has been recommended is large enough and the user’s click-through rate is very high), it means that its Beta distribution is narrow enough and closer to 1.  Random numbers generated according to this distribution tend to be larger, and thus it is more likely to be recommended.</li>
<li>When α + β of an item is very small (the number of times it has been recommended is very small), because the distribution curve it generates is very wide, it is possible to generate a larger random number, and thus be selected for recommendation. This plays the role of exploration.</li>
</ol>
</li>
</ul>
<h2 id="IV-Summary"><a href="#IV-Summary" class="headerlink" title="IV. Summary"></a>IV. Summary</h2><p>Bandit algorithms are a general term for a class of algorithms that can be used to solve the MAB problem of recommendation systems. In fact, it can also be used to solve the cold start problem, which is left for readers to think about. In addition to the Thompson sampling algorithm, common Bandit algorithms also include the UCB algorithm, the Epsilon-greedy algorithm, and others.</p>

</div> 

<script>
    window.onload = detectors();
</script>
    <div class="post-footer">
    <div class="h-line-primary"></div>
    <nav class="post-nav">
        <div class="prev-item">
           
                <div class="icon arrow-left"></div>
                <div class="post-link">
                    <a href="/2025/03/01/netease-ux-articles/news_20211209_28584_990927/">Prev</a>
                </div>
            
        </div>
        <div class="next-item">
            
                <div class="icon arrow-right"></div>
                <div class="post-link">
                  <a href="/2025/03/01/netease-ux-articles/news_20220607_28584_1022838/">Next</a>  
                </div>  
            
        </div>
    </nav>
</div>

    
      <div class="post-comment">

     

     
    
    

</div>
     
  
</article>
        </div>
      </div>
      
      <div class="footer">
    <div class="flex-container">
        <div class="footer-text">
            
            
                
        </div>
    </div>
</div>

    </div>

    
      <div class="search-popup">
    <div class="search-popup-overlay">  
    </div>
    <div class="search-popup-window" >
        <div class="search-header">
            <div class="search-input-container">
              <input autocomplete="off" autocapitalize="off" maxlength="80"
                     placeholder="Search Anything" spellcheck="false"
                     type="search" class="search-input">
            </div>
            <div class="search-close-btn">
                <div class="icon close-btn"></div>
            </div>
        </div>
        <div class="search-result-container">
        </div>
    </div>
</div>

<script>
    const searchConfig = {
        path             : "/search.xml",
        top_n_per_article: "1",
        unescape         : "false",
        trigger: "auto",
        preload: "false"
    }
</script>
<script src="https://cdn.jsdelivr.net/npm/hexo-generator-searchdb@1.4.0/dist/search.js"></script>
<script src="/js/search.js"></script>
    
    

  </body>
</html>
